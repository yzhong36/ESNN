{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ESNN_layers import *\n",
    "import pickle\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import MultiTaskLassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicates = 20\n",
    "dir_path = \"/Users/yzhong36/Desktop/rotation/ESNN/data\"\n",
    "\n",
    "final_cs = []\n",
    "for i in range(1,replicates + 1):\n",
    "#for i in [25]:\n",
    "\n",
    "    #load example data\n",
    "    X = np.loadtxt(os.path.join(dir_path, \"\".join([\"mv_MAPIT_sim_no_same_X\",str(50),\".txt\"])))\n",
    "    Y = np.loadtxt(os.path.join(dir_path, \"\".join([\"mv_MAPIT_sim_no_same_Y\",str(50),\".txt\"])))\n",
    "    X = X.astype('float32')\n",
    "    #X = X[:,:4]\n",
    "    Y = Y.astype('float32')\n",
    "    sample_size = X.shape[0]\n",
    "    all_indices = range(len(Y))\n",
    "    shuffled_indices = tf.random.shuffle(all_indices)\n",
    "    X, Y= tf.gather(X, shuffled_indices), tf.gather(Y, shuffled_indices)\n",
    "    X, Y=X.numpy(), Y.numpy()\n",
    "    X_train_raw_tmp, X_test_tmp, Y_train_raw_tmp, Y_test_tmp = train_test_split(X, Y, test_size=0.15)\n",
    "    \n",
    "    #cov_traits_tmp = [np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]),\n",
    "    #                  np.array([[1, 0.8, 0.8], [0.8, 1, 0.8], [0.8, 0.8, 1]]),\n",
    "    #                  None]\n",
    "    cov_traits_tmp = [np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]),\n",
    "                      np.array([[1, 0.8, 0.8], [0.8, 1, 0.8], [0.8, 0.8, 1]]),\n",
    "                      None]                  \n",
    "\n",
    "    collection_cs = []\n",
    "    for j in range(len(cov_traits_tmp)):\n",
    "        #if (j == Y.shape[1]):\n",
    "        #    X_train_raw = X_train_raw_tmp\n",
    "        #    X_test = X_test_tmp\n",
    "        #    Y_train_raw = Y_train_raw_tmp\n",
    "        #    Y_test = Y_test_tmp\n",
    "        X_train_raw = X_train_raw_tmp\n",
    "        X_test = X_test_tmp\n",
    "        Y_train_raw = Y_train_raw_tmp\n",
    "        Y_test = Y_test_tmp\n",
    "\n",
    "        cov_traits = cov_traits_tmp[j]\n",
    "        #else:\n",
    "        #    X_train_raw = X_train_raw_tmp\n",
    "        #    X_test = X_test_tmp\n",
    "        #    Y_train_raw = Y_train_raw_tmp[:,j]\n",
    "        #    Y_test = Y_test_tmp[:,j]\n",
    "\n",
    "        #parameters setup\n",
    "        model_type = 'regression'\n",
    "        reg_type = 'linear'\n",
    "        L = 5 #number of models\n",
    "        nsample = 1000 #number of samples used for approximate expectation in ELBO\n",
    "        nepoch =50 #training epoch\n",
    "        input_size = X.shape[1]\n",
    "        if len(Y_train_raw.shape) == 1:\n",
    "            output_size = 1\n",
    "        else:\n",
    "            output_size = Y_train_raw.shape[1]\n",
    "\n",
    "        initial_size = X.shape[1]\n",
    "        hidden_sizes = [5]# a list of numbers indicate hidden sizes\n",
    "        lamb = 1.0 #weight parameter in loss function\n",
    "        batch_size = 50 \n",
    "        sigma = 0.0001\n",
    "        temperature = 0.1 #for gumbel-softmax trick\n",
    "        tau = 0.3 #for scale alpha in softmax\n",
    "        mini_loss = np.mean(np.square(Y_test-np.mean(Y_test, axis = 0)))*1.0 #this is used as the threshold for purity\n",
    "        l = 0\n",
    "        iteration = 0\n",
    "        max_iter = 5\n",
    "\n",
    "        #run lasso for init\n",
    "        if output_size == 1:\n",
    "            clf = LassoCV(cv=5, random_state=0).fit(X_train_raw, Y_train_raw)\n",
    "        else:\n",
    "            clf = MultiTaskLassoCV(cv=5, random_state=0).fit(X_train_raw, Y_train_raw)\n",
    "        pred_train = clf.predict(X_train_raw)\n",
    "        acc_train = np.mean((Y_train_raw - pred_train)**2)\n",
    "        pred_test = clf.predict(X_test)\n",
    "        acc_test = np.mean((Y_test - pred_test)**2)\n",
    "        print(f'Lasso Regression| train {acc_train:.4f} test {acc_test:.4f}')\n",
    "\n",
    "        ####################################NN\n",
    "        ##initializations\n",
    "        #if initialize with lasso coefficient\n",
    "        init_val = np.transpose(abs(clf.coef_))\n",
    "        init_val = init_val.astype('float32')\n",
    "        \n",
    "        if output_size == 1:\n",
    "            init_val = np.reshape(init_val, (input_size, 1))\n",
    "\n",
    "        #model\n",
    "        all_model = list()\n",
    "        model = SNN(model_type, reg_type, sigma, input_size, output_size, cov_traits, hidden_sizes, temperature, tau, False, init_val)\n",
    "        all_myloss = list()\n",
    "        all_prbs = list()\n",
    "        #all_cs = list()\n",
    "        all_cs = [[] for i in range(output_size)]\n",
    "        while l<L and iteration<= max_iter:\n",
    "            myloss = np.zeros((nepoch, 4))\n",
    "            for epoch in range(0, nepoch):\n",
    "                learning_rate = 0.005*(0.995**epoch) # for classification\n",
    "                model.optimizer = tf.optimizers.Adam(learning_rate = learning_rate)\n",
    "                all_indices = range(len(Y_train_raw))\n",
    "                shuffled_indices = tf.random.shuffle(all_indices)\n",
    "                train_bnn(model, tf.gather(X_train_raw, shuffled_indices), tf.gather(Y_train_raw, shuffled_indices), batch_size, learning_rate, True, nsample, 0.00005, 10.0)#0.00005\n",
    "                pred, nll, kl = model.call(X_train_raw, Y_train_raw, True, 100)\n",
    "                if output_size == 1:\n",
    "                    temp_train_acc = np.mean(tf.losses.MSE(pred[:,:,0], Y_train_raw))\n",
    "                else:\n",
    "                    temp_train_acc = np.mean(tf.losses.MSE(pred, Y_train_raw))\n",
    "                pred, temp_test_nll, kl = model.call(X_test, Y_test, True, 100)\n",
    "                if output_size == 1:\n",
    "                    temp_test_acc = np.mean(tf.losses.MSE(pred[:,:,0], Y_test))\n",
    "                else:\n",
    "                    temp_test_acc = np.mean(tf.losses.MSE(pred, Y_test))\n",
    "                elbo = nll+kl\n",
    "                myloss[epoch,0] = elbo\n",
    "                myloss[epoch,1] = temp_train_acc\n",
    "                # myloss[epoch,2] = temp_val_acc\n",
    "                myloss[epoch,2] = temp_test_acc\n",
    "                print(\"Iteration\", iteration)\n",
    "                print(\"Train loss\", temp_train_acc)\n",
    "                print(\"l\", l)\n",
    "                print(\"mini loss\", mini_loss)\n",
    "                print(\"Test loss\", temp_test_acc)\n",
    "                #prbs = np.asarray(tf.nn.softmax(model.bnn.w_alpha[:,0]/tau))\n",
    "                prbs = np.asarray(tf.map_fn(tf.nn.softmax, tf.transpose(model.bnn.w_alpha/tau)))\n",
    "                print('#################################################################################################################')\n",
    "                for i in range(prbs.shape[0]):\n",
    "                    print(\"Trait\",i+1,\":\")\n",
    "                    print(np.where(prbs[i,]>0.1))\n",
    "                    print(np.where(prbs[i,] == np.max(prbs[i,])))\n",
    "                #print(np.where(prbs>0.1))\n",
    "                #print(np.where(prbs == np.max(prbs)))\n",
    "                \n",
    "                #cov = tf.matmul(tf.transpose(model.bnn.cov_decomp,perm=[0,1,3,2]), tf.transpose(model.bnn.cov_decomp,perm=[0,1,2,3]))\n",
    "                #cov = model.bnn.cov\n",
    "                #print(cov[0,0,:,:])\n",
    "                if epoch>3 and model_type == 'regression' and temp_test_acc<mini_loss - 0.05:\n",
    "                    break\n",
    "                if epoch>10 and model_type == 'regression' and temp_test_acc<mini_loss - 0.02:\n",
    "                    break\n",
    "                if epoch > 30:\n",
    "                    curr_avg = np.max(myloss[epoch-2:epoch,2])\n",
    "                    pre_avg = np.max(myloss[epoch-4:epoch-2,2])\n",
    "                    if model_type == 'regression' and curr_avg>= pre_avg:\n",
    "                        break\n",
    "            if model_type == 'regression' and myloss[epoch,2]<=mini_loss-0.01:\n",
    "                mini_loss = myloss[epoch,2]\n",
    "                l += 1\n",
    "                all_myloss.append(myloss)\n",
    "                all_model.append(model)\n",
    "                #temp_prbs = np.asarray(tf.nn.softmax(model.bnn.w_alpha[:,0]/tau))\n",
    "                temp_prbs = np.asarray(tf.map_fn(tf.nn.softmax, tf.transpose(model.bnn.w_alpha/tau)))\n",
    "                if temp_prbs.shape[1]<initial_size:\n",
    "                    #if len(all_cs) == 1:\n",
    "                        #toinsert = np.unique(all_cs[0])\n",
    "                    #else:\n",
    "                    toinsert = np.unique(np.concatenate(sum(all_cs, [])))\n",
    "                    temp_to_add = temp_prbs\n",
    "                    for pos in toinsert:\n",
    "                        temp_to_add = np.insert(temp_to_add, pos, 1e-10, axis = 1)\n",
    "                    all_prbs.append(temp_to_add)\n",
    "                else:\n",
    "                    temp_to_add = temp_prbs\n",
    "                    all_prbs.append(temp_to_add)\n",
    "                #derive residuals\n",
    "                pred, nll, kl = model.call(X_train_raw, Y_train_raw, True, 100)\n",
    "                if output_size == 1:\n",
    "                    res_train = np.mean(pred[:,:,0], axis = 0) - Y_train_raw\n",
    "                else:\n",
    "                    res_train = np.mean(pred, axis = 0) - Y_train_raw\n",
    "                pred, temp_test_nll, kl = model.call(X_test, Y_test, True, 100)\n",
    "                if output_size == 1:\n",
    "                    res_test = np.mean(pred[:,:,0], axis = 0) - Y_test\n",
    "                else:\n",
    "                    res_test = np.mean(pred, axis = 0) - Y_test\n",
    "                Y_train_raw = res_train\n",
    "                Y_test = res_test\n",
    "                #compute cs\n",
    "                nsnp = temp_prbs.shape[1]\n",
    "                temp_cs_list = []\n",
    "                 \n",
    "                for trait in range(temp_prbs.shape[0]):\n",
    "                    for temp_j in range(nsnp):\n",
    "                        cs_idx = nsnp-temp_j\n",
    "                        if sum(np.sort(temp_prbs[trait,:])[cs_idx:])>0.95:\n",
    "                            break\n",
    "                    temp_cs = np.argsort(temp_prbs[trait,:])[cs_idx:]\n",
    "                    if temp_cs.shape[0]>1:\n",
    "                        cc = np.corrcoef(np.transpose(X[:,temp_cs]))\n",
    "                        for k in range(cc.shape[0]):\n",
    "                            cc[k][k]=0.5\n",
    "                    else:\n",
    "                        cc = 0.5\n",
    "                    if np.min(cc)>=0.5:\n",
    "                        #print(\"temp_cs: \", temp_cs)\n",
    "                        #print(\"cc: \",cc)\n",
    "                        # all_cs.append(temp_cs)\n",
    "                        #remove found variables\n",
    "                        temp_cs_list.append(temp_cs)\n",
    "                        #add cs with correct idx\n",
    "                        #print(\"temp_to_add shape: \", temp_to_add.shape)\n",
    "                        nsnp = temp_to_add.shape[1]\n",
    "                        for temp_j in range(nsnp):\n",
    "                            cs_idx = nsnp-temp_j\n",
    "                            if sum(np.sort(temp_to_add[trait,:])[cs_idx:])>0.95:\n",
    "                                break\n",
    "                        temp_cs = np.argsort(temp_to_add[trait,:])[cs_idx:]\n",
    "                        all_cs[trait].append(temp_cs)\n",
    "\n",
    "                if len(temp_cs_list) > 0:\n",
    "                    temp_cs = np.unique(np.concatenate(temp_cs_list))\n",
    "                    print(\"Regress out: \", temp_cs)\n",
    "                    print(\"Prob: \", temp_prbs[:, temp_cs])\n",
    "                    X_train_raw = np.delete(X_train_raw, temp_cs, axis = 1)\n",
    "                    X_test = np.delete(X_test, temp_cs, axis = 1)\n",
    "                    input_size = X_train_raw.shape[1]\n",
    "                \n",
    "            #if len(all_cs)>0:\n",
    "            print(\"Current CS: \",all_cs)\n",
    "            if len(sum(all_cs, [])) > 0:\n",
    "                temp_init_val = tf.random.truncated_normal([input_size, output_size], mean=0.0, stddev=0.1, dtype=tf.dtypes.float32)\n",
    "            else:\n",
    "                temp_init_val = init_val\n",
    "            model = SNN(model_type, reg_type, sigma, input_size, output_size, cov_traits, hidden_sizes, temperature, tau, False, temp_init_val)\n",
    "            iteration+=1\n",
    "\n",
    "        collection_cs.append(all_cs)\n",
    "    final_cs.append(collection_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_cs = final_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicates = 20\n",
    "dir_path = \"/Users/yzhong36/Desktop/rotation/ESNN/data\"\n",
    "\n",
    "final_cs = []\n",
    "for i in range(1,replicates + 1):\n",
    "#for i in [25]:\n",
    "\n",
    "    #load example data\n",
    "    X = np.loadtxt(os.path.join(dir_path, \"\".join([\"mv_MAPIT_sim_no_same_X\",str(50),\".txt\"])))\n",
    "    Y = np.loadtxt(os.path.join(dir_path, \"\".join([\"mv_MAPIT_sim_no_same_Y\",str(50),\".txt\"])))\n",
    "    X = X.astype('float32')\n",
    "    #X = X[:,:4]\n",
    "    Y = Y.astype('float32')\n",
    "    sample_size = X.shape[0]\n",
    "    all_indices = range(len(Y))\n",
    "    shuffled_indices = tf.random.shuffle(all_indices)\n",
    "    X, Y= tf.gather(X, shuffled_indices), tf.gather(Y, shuffled_indices)\n",
    "    X, Y=X.numpy(), Y.numpy()\n",
    "    X_train_raw_tmp, X_test_tmp, Y_train_raw_tmp, Y_test_tmp = train_test_split(X, Y, test_size=0.15)\n",
    "    \n",
    "    cov_traits_tmp = [np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]),\n",
    "                      np.array([[1, 0.8, 0.8], [0.8, 1, 0.8], [0.8, 0.8, 1]]),\n",
    "                      None]\n",
    "    #cov_traits_tmp = [\n",
    "    #                  None]                  \n",
    "\n",
    "    collection_cs = []\n",
    "    for j in range(Y.shape[1]):\n",
    "        #if (j == Y.shape[1]):\n",
    "        #    X_train_raw = X_train_raw_tmp\n",
    "        #    X_test = X_test_tmp\n",
    "        #    Y_train_raw = Y_train_raw_tmp\n",
    "        #    Y_test = Y_test_tmp\n",
    "        X_train_raw = X_train_raw_tmp\n",
    "        X_test = X_test_tmp\n",
    "        Y_train_raw = Y_train_raw_tmp[:,j]\n",
    "        Y_test = Y_test_tmp[:,j]\n",
    "\n",
    "        cov_traits = cov_traits_tmp[j]\n",
    "        #else:\n",
    "        #    X_train_raw = X_train_raw_tmp\n",
    "        #    X_test = X_test_tmp\n",
    "        #    Y_train_raw = Y_train_raw_tmp[:,j]\n",
    "        #    Y_test = Y_test_tmp[:,j]\n",
    "\n",
    "        #parameters setup\n",
    "        model_type = 'regression'\n",
    "        reg_type = 'linear'\n",
    "        L = 5 #number of models\n",
    "        nsample = 1000 #number of samples used for approximate expectation in ELBO\n",
    "        nepoch =50 #training epoch\n",
    "        input_size = X.shape[1]\n",
    "        if len(Y_train_raw.shape) == 1:\n",
    "            output_size = 1\n",
    "        else:\n",
    "            output_size = Y_train_raw.shape[1]\n",
    "\n",
    "        initial_size = X.shape[1]\n",
    "        hidden_sizes = [5]# a list of numbers indicate hidden sizes\n",
    "        lamb = 1.0 #weight parameter in loss function\n",
    "        batch_size = 50 \n",
    "        sigma = 0.0001\n",
    "        temperature = 0.1 #for gumbel-softmax trick\n",
    "        tau = 0.3 #for scale alpha in softmax\n",
    "        mini_loss = np.mean(np.square(Y_test-np.mean(Y_test, axis = 0)))*1.0 #this is used as the threshold for purity\n",
    "        l = 0\n",
    "        iteration = 0\n",
    "        max_iter = 5\n",
    "\n",
    "        #run lasso for init\n",
    "        if output_size == 1:\n",
    "            clf = LassoCV(cv=5, random_state=0, precompute = False).fit(X_train_raw, Y_train_raw)\n",
    "        else:\n",
    "            clf = MultiTaskLassoCV(cv=5, random_state=0).fit(X_train_raw, Y_train_raw)\n",
    "        pred_train = clf.predict(X_train_raw)\n",
    "        acc_train = np.mean((Y_train_raw - pred_train)**2)\n",
    "        pred_test = clf.predict(X_test)\n",
    "        acc_test = np.mean((Y_test - pred_test)**2)\n",
    "        print(f'Lasso Regression| train {acc_train:.4f} test {acc_test:.4f}')\n",
    "\n",
    "        ####################################NN\n",
    "        ##initializations\n",
    "        #if initialize with lasso coefficient\n",
    "        init_val = np.transpose(abs(clf.coef_))\n",
    "        init_val = init_val.astype('float32')\n",
    "        \n",
    "        if output_size == 1:\n",
    "            init_val = np.reshape(init_val, (input_size, 1))\n",
    "\n",
    "        #model\n",
    "        all_model = list()\n",
    "        model = SNN(model_type, reg_type, sigma, input_size, output_size, cov_traits, hidden_sizes, temperature, tau, False, init_val)\n",
    "        all_myloss = list()\n",
    "        all_prbs = list()\n",
    "        #all_cs = list()\n",
    "        all_cs = [[] for i in range(output_size)]\n",
    "        while l<L and iteration<= max_iter:\n",
    "            myloss = np.zeros((nepoch, 4))\n",
    "            for epoch in range(0, nepoch):\n",
    "                learning_rate = 0.005*(0.995**epoch) # for classification\n",
    "                model.optimizer = tf.optimizers.Adam(learning_rate = learning_rate)\n",
    "                all_indices = range(len(Y_train_raw))\n",
    "                shuffled_indices = tf.random.shuffle(all_indices)\n",
    "                train_bnn(model, tf.gather(X_train_raw, shuffled_indices), tf.gather(Y_train_raw, shuffled_indices), batch_size, learning_rate, True, nsample, 0.00005, 10.0)#0.00005\n",
    "                pred, nll, kl = model.call(X_train_raw, Y_train_raw, True, 100)\n",
    "                if output_size == 1:\n",
    "                    temp_train_acc = np.mean(tf.losses.MSE(pred[:,:,0], Y_train_raw))\n",
    "                else:\n",
    "                    temp_train_acc = np.mean(tf.losses.MSE(pred, Y_train_raw))\n",
    "                pred, temp_test_nll, kl = model.call(X_test, Y_test, True, 100)\n",
    "                if output_size == 1:\n",
    "                    temp_test_acc = np.mean(tf.losses.MSE(pred[:,:,0], Y_test))\n",
    "                else:\n",
    "                    temp_test_acc = np.mean(tf.losses.MSE(pred, Y_test))\n",
    "                elbo = nll+kl\n",
    "                myloss[epoch,0] = elbo\n",
    "                myloss[epoch,1] = temp_train_acc\n",
    "                # myloss[epoch,2] = temp_val_acc\n",
    "                myloss[epoch,2] = temp_test_acc\n",
    "                print(\"Iteration\", iteration)\n",
    "                print(\"Train loss\", temp_train_acc)\n",
    "                print(\"l\", l)\n",
    "                print(\"mini loss\", mini_loss)\n",
    "                print(\"Test loss\", temp_test_acc)\n",
    "                #prbs = np.asarray(tf.nn.softmax(model.bnn.w_alpha[:,0]/tau))\n",
    "                prbs = np.asarray(tf.map_fn(tf.nn.softmax, tf.transpose(model.bnn.w_alpha/tau)))\n",
    "                print('#################################################################################################################')\n",
    "                for i in range(prbs.shape[0]):\n",
    "                    print(\"Trait\",i+1,\":\")\n",
    "                    print(np.where(prbs[i,]>0.1))\n",
    "                    print(np.where(prbs[i,] == np.max(prbs[i,])))\n",
    "                #print(np.where(prbs>0.1))\n",
    "                #print(np.where(prbs == np.max(prbs)))\n",
    "                \n",
    "                #cov = tf.matmul(tf.transpose(model.bnn.cov_decomp,perm=[0,1,3,2]), tf.transpose(model.bnn.cov_decomp,perm=[0,1,2,3]))\n",
    "                #cov = model.bnn.cov\n",
    "                #print(cov[0,0,:,:])\n",
    "                if epoch>3 and model_type == 'regression' and temp_test_acc<mini_loss - 0.05:\n",
    "                    break\n",
    "                if epoch>10 and model_type == 'regression' and temp_test_acc<mini_loss - 0.02:\n",
    "                    break\n",
    "                if epoch > 30:\n",
    "                    curr_avg = np.max(myloss[epoch-2:epoch,2])\n",
    "                    pre_avg = np.max(myloss[epoch-4:epoch-2,2])\n",
    "                    if model_type == 'regression' and curr_avg>= pre_avg:\n",
    "                        break\n",
    "            if model_type == 'regression' and myloss[epoch,2]<=mini_loss-0.01:\n",
    "                mini_loss = myloss[epoch,2]\n",
    "                l += 1\n",
    "                all_myloss.append(myloss)\n",
    "                all_model.append(model)\n",
    "                #temp_prbs = np.asarray(tf.nn.softmax(model.bnn.w_alpha[:,0]/tau))\n",
    "                temp_prbs = np.asarray(tf.map_fn(tf.nn.softmax, tf.transpose(model.bnn.w_alpha/tau)))\n",
    "                if temp_prbs.shape[1]<initial_size:\n",
    "                    #if len(all_cs) == 1:\n",
    "                        #toinsert = np.unique(all_cs[0])\n",
    "                    #else:\n",
    "                    toinsert = np.unique(np.concatenate(sum(all_cs, [])))\n",
    "                    temp_to_add = temp_prbs\n",
    "                    for pos in toinsert:\n",
    "                        temp_to_add = np.insert(temp_to_add, pos, 1e-10, axis = 1)\n",
    "                    all_prbs.append(temp_to_add)\n",
    "                else:\n",
    "                    temp_to_add = temp_prbs\n",
    "                    all_prbs.append(temp_to_add)\n",
    "                #derive residuals\n",
    "                pred, nll, kl = model.call(X_train_raw, Y_train_raw, True, 100)\n",
    "                if output_size == 1:\n",
    "                    res_train = np.mean(pred[:,:,0], axis = 0) - Y_train_raw\n",
    "                else:\n",
    "                    res_train = np.mean(pred, axis = 0) - Y_train_raw\n",
    "                pred, temp_test_nll, kl = model.call(X_test, Y_test, True, 100)\n",
    "                if output_size == 1:\n",
    "                    res_test = np.mean(pred[:,:,0], axis = 0) - Y_test\n",
    "                else:\n",
    "                    res_test = np.mean(pred, axis = 0) - Y_test\n",
    "                Y_train_raw = res_train\n",
    "                Y_test = res_test\n",
    "                #compute cs\n",
    "                nsnp = temp_prbs.shape[1]\n",
    "                temp_cs_list = []\n",
    "                 \n",
    "                for trait in range(temp_prbs.shape[0]):\n",
    "                    for temp_j in range(nsnp):\n",
    "                        cs_idx = nsnp-temp_j\n",
    "                        if sum(np.sort(temp_prbs[trait,:])[cs_idx:])>0.95:\n",
    "                            break\n",
    "                    temp_cs = np.argsort(temp_prbs[trait,:])[cs_idx:]\n",
    "                    if temp_cs.shape[0]>1:\n",
    "                        cc = np.corrcoef(np.transpose(X[:,temp_cs]))\n",
    "                        for k in range(cc.shape[0]):\n",
    "                            cc[k][k]=0.5\n",
    "                    else:\n",
    "                        cc = 0.5\n",
    "                    if np.min(cc)>=0.5:\n",
    "                        #print(\"temp_cs: \", temp_cs)\n",
    "                        #print(\"cc: \",cc)\n",
    "                        # all_cs.append(temp_cs)\n",
    "                        #remove found variables\n",
    "                        temp_cs_list.append(temp_cs)\n",
    "                        #add cs with correct idx\n",
    "                        #print(\"temp_to_add shape: \", temp_to_add.shape)\n",
    "                        nsnp = temp_to_add.shape[1]\n",
    "                        for temp_j in range(nsnp):\n",
    "                            cs_idx = nsnp-temp_j\n",
    "                            if sum(np.sort(temp_to_add[trait,:])[cs_idx:])>0.95:\n",
    "                                break\n",
    "                        temp_cs = np.argsort(temp_to_add[trait,:])[cs_idx:]\n",
    "                        all_cs[trait].append(temp_cs)\n",
    "\n",
    "                if len(temp_cs_list) > 0:\n",
    "                    temp_cs = np.unique(np.concatenate(temp_cs_list))\n",
    "                    print(\"Regress out: \", temp_cs)\n",
    "                    print(\"Prob: \", temp_prbs[:, temp_cs])\n",
    "                    X_train_raw = np.delete(X_train_raw, temp_cs, axis = 1)\n",
    "                    X_test = np.delete(X_test, temp_cs, axis = 1)\n",
    "                    input_size = X_train_raw.shape[1]\n",
    "                \n",
    "            #if len(all_cs)>0:\n",
    "            print(\"Current CS: \",all_cs)\n",
    "            if len(sum(all_cs, [])) > 0:\n",
    "                temp_init_val = tf.random.truncated_normal([input_size, output_size], mean=0.0, stddev=0.1, dtype=tf.dtypes.float32)\n",
    "            else:\n",
    "                temp_init_val = init_val\n",
    "            model = SNN(model_type, reg_type, sigma, input_size, output_size, cov_traits, hidden_sizes, temperature, tau, False, temp_init_val)\n",
    "            iteration+=1\n",
    "\n",
    "        collection_cs.append(all_cs)\n",
    "    final_cs.append(collection_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_cs = final_cs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34832a257fc150464597eef141669310de6c450302703993bd0b519e1861137d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
